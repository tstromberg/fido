# bdcache - Big Dumb Cache

<img src="media/logo-small.png" alt="bdcache logo" width="256">

[![Go Reference](https://pkg.go.dev/badge/github.com/codeGROOVE-dev/bdcache.svg)](https://pkg.go.dev/github.com/codeGROOVE-dev/bdcache)
[![Go Report Card](https://goreportcard.com/badge/github.com/codeGROOVE-dev/bdcache)](https://goreportcard.com/report/github.com/codeGROOVE-dev/bdcache)
[![License](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](https://opensource.org/licenses/Apache-2.0)

<br clear="right">

Stupid fast in-memory Go cache with optional L2 persistence layer.

## Install

```bash
go get github.com/codeGROOVE-dev/bdcache
```

## Use

```go
import (
    "github.com/codeGROOVE-dev/bdcache"
    "github.com/codeGROOVE-dev/bdcache/persist/localfs"
)

// Memory only
cache, _ := bdcache.New[string, int](ctx)
cache.Set(ctx, "answer", 42, 0)           // Synchronous: returns after persistence completes
cache.SetAsync(ctx, "answer", 42, 0)      // Async: returns immediately, persists in background
val, found, _ := cache.Get(ctx, "answer")

// With local file persistence
p, _ := localfs.New[string, User]("myapp", "")
cache, _ := bdcache.New[string, User](ctx,
    bdcache.WithPersistence(p))

// With Valkey/Redis persistence
p, _ := valkey.New[string, User](ctx, "myapp", "localhost:6379")
cache, _ := bdcache.New[string, User](ctx,
    bdcache.WithPersistence(p))

// Cloud Run auto-detection (datastore in Cloud Run, localfs elsewhere)
p, _ := cloudrun.New[string, User](ctx, "myapp")
cache, _ := bdcache.New[string, User](ctx,
    bdcache.WithPersistence(p))
```

## Features

- **Faster than a bat out of hell** - Low latency, high throughput
- **S3-FIFO eviction** - Better hit-rates than LRU ([learn more](https://s3fifo.com/))
- **Pluggable persistence** - Bring your own database or use built-in backends:
  - [`persist/localfs`](persist/localfs) - Local files (gob encoding, zero dependencies)
  - [`persist/datastore`](persist/datastore) - Google Cloud Datastore
  - [`persist/valkey`](persist/valkey) - Valkey/Redis
  - [`persist/cloudrun`](persist/cloudrun) - Auto-detect Cloud Run
- **Per-item TTL** - Optional expiration
- **Graceful degradation** - Cache works even if persistence fails
- **Zero allocation reads** - minimal GC thrashing
- **Type safe** - Go generics

## Performance against the Competition

bdcache prioritizes high hit-rates and low read latency, but it performs quite well all around.

Here's the results from an M4 MacBook Pro - run `make bench` to see the results for yourself:

### Hit Rate (Zipf Î±=0.99, 1M ops, 1M keyspace)

| Cache         | Size=1% | Size=2.5% | Size=5% |
|---------------|---------|-----------|---------|
| bdcache ğŸŸ¡    |  94.46% |    94.89% |  95.09% |
| otter ğŸ¦¦      |  94.28% |    94.69% |  95.09% |
| ristretto â˜•  |  91.62% |    92.45% |  93.03% |
| tinylfu ğŸ”¬    |  94.31% |    94.87% |  95.09% |
| freecache ğŸ†“  |  94.03% |    94.15% |  94.75% |
| lru ğŸ“š        |  94.10% |    94.84% |  95.09% |

ğŸ† Hit rate: +0.1% better than 2nd best (tinylfu)

### Single-Threaded Latency (sorted by Get)

| Cache         | Get ns/op | Get B/op | Get allocs | Set ns/op | Set B/op | Set allocs |
|---------------|-----------|----------|------------|-----------|----------|------------|
| bdcache ğŸŸ¡    |       9.0 |        0 |          0 |      21.0 |        0 |          0 |
| lru ğŸ“š        |      24.0 |        0 |          0 |      23.0 |        0 |          0 |
| ristretto â˜•  |      32.0 |       14 |          0 |      67.0 |      119 |          3 |
| otter ğŸ¦¦      |      35.0 |        0 |          0 |     140.0 |       51 |          1 |
| freecache ğŸ†“  |      73.0 |       15 |          1 |      58.0 |        4 |          0 |
| tinylfu ğŸ”¬    |      88.0 |        3 |          0 |     107.0 |      175 |          3 |

ğŸ† Get latency: +167% faster than 2nd best (lru)
ğŸ† Set latency: +9.5% faster than 2nd best (lru)

### Single-Threaded Throughput (mixed read/write)

| Cache         | Get QPS    | Set QPS    |
|---------------|------------|------------|
| bdcache ğŸŸ¡    |   75.49M   |   41.56M   |
| lru ğŸ“š        |   34.86M   |   35.33M   |
| ristretto â˜•  |   28.38M   |   13.59M   |
| otter ğŸ¦¦      |   25.59M   |    7.17M   |
| freecache ğŸ†“  |   12.79M   |   15.80M   |
| tinylfu ğŸ”¬    |   10.77M   |    8.94M   |

ğŸ† Get throughput: +117% faster than 2nd best (lru)
ğŸ† Set throughput: +18% faster than 2nd best (lru)

### Concurrent Throughput (mixed read/write): 4 threads

| Cache         | Get QPS    | Set QPS    |
|---------------|------------|------------|
| bdcache ğŸŸ¡    |   29.51M   |   31.43M   |
| otter ğŸ¦¦      |   28.96M   |    4.17M   |
| ristretto â˜•  |   27.16M   |   13.23M   |
| freecache ğŸ†“  |   25.06M   |   21.94M   |
| lru ğŸ“š        |    9.43M   |    9.59M   |
| tinylfu ğŸ”¬    |    5.51M   |    4.85M   |

ğŸ† Get throughput: +1.9% faster than 2nd best (otter)
ğŸ† Set throughput: +43% faster than 2nd best (freecache)

### Concurrent Throughput (mixed read/write): 8 threads

| Cache         | Get QPS    | Set QPS    |
|---------------|------------|------------|
| bdcache ğŸŸ¡    |   22.16M   |   18.82M   |
| otter ğŸ¦¦      |   19.51M   |    3.14M   |
| ristretto â˜•  |   18.62M   |   11.60M   |
| freecache ğŸ†“  |   16.60M   |   15.92M   |
| lru ğŸ“š        |    7.62M   |    7.75M   |
| tinylfu ğŸ”¬    |    4.95M   |    4.26M   |

ğŸ† Get throughput: +14% faster than 2nd best (otter)
ğŸ† Set throughput: +18% faster than 2nd best (freecache)

### Concurrent Throughput (mixed read/write): 12 threads

| Cache         | Get QPS    | Set QPS    |
|---------------|------------|------------|
| bdcache ğŸŸ¡    |   24.29M   |   24.21M   |
| ristretto â˜•  |   22.76M   |   11.54M   |
| otter ğŸ¦¦      |   21.65M   |    2.79M   |
| freecache ğŸ†“  |   17.25M   |   16.53M   |
| lru ğŸ“š        |    7.58M   |    7.62M   |
| tinylfu ğŸ”¬    |    4.51M   |    3.87M   |

ğŸ† Get throughput: +6.7% faster than 2nd best (ristretto)
ğŸ† Set throughput: +47% faster than 2nd best (freecache)

### Concurrent Throughput (mixed read/write): 16 threads

| Cache         | Get QPS    | Set QPS    |
|---------------|------------|------------|
| bdcache ğŸŸ¡    |   16.24M   |   15.77M   |
| otter ğŸ¦¦      |   16.02M   |    2.76M   |
| ristretto â˜•  |   15.41M   |   12.50M   |
| freecache ğŸ†“  |   15.05M   |   14.61M   |
| lru ğŸ“š        |    7.45M   |    7.47M   |
| tinylfu ğŸ”¬    |    4.71M   |    3.61M   |

ğŸ† Get throughput: +1.4% faster than 2nd best (otter)
ğŸ† Set throughput: +8.0% faster than 2nd best (freecache)

### Concurrent Throughput (mixed read/write): 24 threads

| Cache         | Get QPS    | Set QPS    |
|---------------|------------|------------|
| bdcache ğŸŸ¡    |   16.16M   |   15.47M   |
| otter ğŸ¦¦      |   15.80M   |    2.87M   |
| ristretto â˜•  |   15.48M   |   13.28M   |
| freecache ğŸ†“  |   14.92M   |   14.36M   |
| lru ğŸ“š        |    7.69M   |    7.59M   |
| tinylfu ğŸ”¬    |    5.03M   |    3.84M   |

ğŸ† Get throughput: +2.3% faster than 2nd best (otter)
ğŸ† Set throughput: +7.7% faster than 2nd best (freecache)

### Concurrent Throughput (mixed read/write): 32 threads

| Cache         | Get QPS    | Set QPS    |
|---------------|------------|------------|
| bdcache ğŸŸ¡    |   15.85M   |   15.41M   |
| otter ğŸ¦¦      |   15.71M   |    2.85M   |
| ristretto â˜•  |   15.60M   |   13.16M   |
| freecache ğŸ†“  |   14.33M   |   14.13M   |
| lru ğŸ“š        |    7.70M   |    8.07M   |
| tinylfu ğŸ”¬    |    5.32M   |    2.99M   |

ğŸ† Get throughput: +0.9% faster than 2nd best (otter)
ğŸ† Set throughput: +9.1% faster than 2nd best (freecache)

NOTE: Performance characteristics often have trade-offs. There are almost certainly workloads where other cache implementations are faster, but nobody blends speed and persistence the way that bdcache does.

## License

Apache 2.0
