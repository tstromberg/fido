package multicache

import (
	"fmt"
	"math/bits"
	"runtime"
	"sync"
	"sync/atomic"
	"time"
	"unsafe"
)

// wyhash constants for fast string hashing.
const (
	wyp0 = 0xa0761d6478bd642f
	wyp1 = 0xe7037ed1a0b428db
)

// wyhashString is a fast hash function for strings.
// Adapted from wyhash (https://github.com/wangyi-fudan/wyhash).
// About 2.6x faster than maphash.String with acceptable distribution.
func wyhashString(s string) uint64 {
	n := len(s)
	if n == 0 {
		return 0
	}

	p := unsafe.Pointer(unsafe.StringData(s))
	var a, b uint64

	if n <= 8 {
		if n >= 4 {
			a = uint64(*(*uint32)(p))
			b = uint64(*(*uint32)(unsafe.Add(p, n-4)))
		} else {
			a = uint64(*(*byte)(p))<<16 | uint64(*(*byte)(unsafe.Add(p, n>>1)))<<8 | uint64(*(*byte)(unsafe.Add(p, n-1)))
			b = 0
		}
	} else {
		a = *(*uint64)(p)
		b = *(*uint64)(unsafe.Add(p, n-8))
	}

	// wymix
	hi, lo := bits.Mul64(a^wyp0, b^uint64(n)^wyp1)
	return hi ^ lo
}

const maxShards = 2048

// maxFreq is the maximum frequency counter value (0-7).
// Higher values give better resolution for distinguishing hot items.
const maxFreq = 7

// s3fifo implements the S3-FIFO eviction algorithm from SOSP'23 paper
// "FIFO queues are all you need for cache eviction"
//
// This implementation uses dynamic sharding for improved concurrent performance.
// The number of shards is determined by capacity to ensure each shard has enough
// entries for the S3-FIFO algorithm to work effectively.
// Each shard is an independent S3-FIFO instance with its own queues and lock.
//
// Algorithm per shard:
// - Small queue (S): ~10% of shard capacity, for new entries
// - Main queue (M): ~90% of shard capacity, for promoted entries
// - Ghost queue (G): Tracks evicted keys (no data)
//
// On cache miss:
//   - If entry not in ghost → insert into Small
//   - If entry in ghost → insert into Main (was accessed before)
//
// On eviction from Small:
//   - If freq == 0 → evict and add to ghost
//   - If freq > 0 → promote to Main and reset freq to 0
//
// On eviction from Main:
//   - If freq == 0 → evict (don't add to ghost, already there)
//   - If freq > 0 → reinsert to back of Main and decrement freq (lazy promotion)

type s3fifo[K comparable, V any] struct {
	shards      []*shard[K, V]
	numShards   int
	shardMask   uint64 // For fast modulo via bitwise AND
	keyIsInt    bool   // Fast path flag for int keys
	keyIsInt64  bool   // Fast path flag for int64 keys
	keyIsString bool   // Fast path flag for string keys

	// Global capacity tracking ensures exactly Size() entries can be stored,
	// regardless of hash distribution across shards.
	totalEntries atomic.Int64
	capacity     int
}

// shard is an independent S3-FIFO cache partition.
// Uses RWMutex for read-heavy workloads; sharding reduces contention across goroutines.
// The entries map provides O(1) lookup while intrusive lists maintain queue order.
//
//nolint:govet // fieldalignment: padding is intentional to prevent false sharing
type shard[K comparable, V any] struct {
	mu      sync.RWMutex       // RWMutex is faster for read-heavy workloads with sharding
	_       [40]byte           // Padding to cache line boundary
	entries map[K]*entry[K, V] // Direct map access (protected by mu)
	small   entryList[K, V]    // Intrusive list for small queue
	main    entryList[K, V]    // Intrusive list for main queue

	// Two-stage Bloom filter ghost: tracks recently evicted keys with low memory overhead.
	// Two filters rotate to provide approximate FIFO.
	// When ghostActive fills up, ghostAging is cleared and they swap roles.
	ghostActive     *bloomFilter
	ghostAging      *bloomFilter
	ghostFreqActive map[uint64]uint32 // Frequency at eviction time (rotates with bloom)
	ghostFreqAging  map[uint64]uint32
	ghostCap        int
	hasher          func(K) uint64

	capacity int

	// Free list for reducing allocations
	freeEntries *entry[K, V]

	// Warmup: during initial fill, admit everything without eviction checks
	warmupComplete bool

	// Parent pointer for global capacity tracking
	parent *s3fifo[K, V]
}

// entryList is an intrusive doubly-linked list for cache entries.
// Zero value is a valid empty list.
type entryList[K comparable, V any] struct {
	head *entry[K, V]
	tail *entry[K, V]
	len  int
}

func (l *entryList[K, V]) pushBack(e *entry[K, V]) {
	e.prev = l.tail
	e.next = nil
	if l.tail != nil {
		l.tail.next = e
	} else {
		l.head = e
	}
	l.tail = e
	l.len++
}

func (l *entryList[K, V]) remove(e *entry[K, V]) {
	if e.prev != nil {
		e.prev.next = e.next
	} else {
		l.head = e.next
	}
	if e.next != nil {
		e.next.prev = e.prev
	} else {
		l.tail = e.prev
	}
	e.prev = nil
	e.next = nil
	l.len--
}

// timeToNano converts a time.Time to Unix nanoseconds, returning 0 for zero time.
func timeToNano(t time.Time) int64 {
	if t.IsZero() {
		return 0
	}
	return t.UnixNano()
}

// entry represents a cached value with metadata.
type entry[K comparable, V any] struct {
	key        K
	value      V
	prev       *entry[K, V] // Intrusive list pointers
	next       *entry[K, V]
	expiryNano int64         // Unix nanoseconds; 0 means no expiry
	freq       atomic.Uint32 // Frequency counter (0-7) for S3-FIFO eviction decisions; atomic for lock-free reads
	peakFreq   atomic.Uint32 // Peak frequency achieved (for ghost restore); atomic for lock-free updates
	inSmall    bool          // True if in Small queue, false if in Main
}

// newS3FIFO creates a new sharded S3-FIFO cache with the given total capacity.
func newS3FIFO[K comparable, V any](cfg *config) *s3fifo[K, V] {
	capacity := cfg.size
	if capacity <= 0 {
		capacity = 16384
	}

	// More shards reduces lock contention, but too many shards causes capacity
	// loss due to hash distribution imbalance. Use 2x GOMAXPROCS as a balance
	// between concurrency and capacity efficiency.
	minShards := runtime.GOMAXPROCS(0) * 2
	// Each shard needs enough entries for good hash distribution (95%+ efficiency).
	// With 256 entries per shard, hash variance is diluted enough for consistent efficiency.
	const minEntriesPerShard = 256
	maxByCapacity := max(1, capacity/minEntriesPerShard)
	nshards := min(minShards, maxByCapacity, maxShards)
	// Round to power of 2 for fast modulo.
	//nolint:gosec // G115: nshards bounded by [1, maxShards]
	nshards = 1 << (bits.Len(uint(nshards)) - 1)

	shardCap := (capacity + nshards - 1) / nshards // ceiling division

	cache := &s3fifo[K, V]{
		shards:    make([]*shard[K, V], nshards),
		numShards: nshards,
		//nolint:gosec // G115: nshards bounded by [1, maxShards]
		shardMask: uint64(nshards - 1),
		capacity:  capacity,
	}

	// Detect key type at construction time to enable fast-path hash functions.
	// This avoids the type switch overhead on every Get/Set call.
	var zeroKey K
	switch any(zeroKey).(type) {
	case int:
		cache.keyIsInt = true
	case int64:
		cache.keyIsInt64 = true
	case string:
		cache.keyIsString = true
	}

	// Ghost queue at 100% of shard capacity matches reference implementation.
	const ghostRatio = 1.0

	// Prepare hasher for Bloom filter
	var hasher func(K) uint64
	switch {
	case cache.keyIsInt:
		hasher = func(key K) uint64 {
			return hashInt64(int64(*(*int)(unsafe.Pointer(&key))))
		}
	case cache.keyIsInt64:
		hasher = func(key K) uint64 {
			return hashInt64(*(*int64)(unsafe.Pointer(&key)))
		}
	case cache.keyIsString:
		hasher = func(key K) uint64 {
			return wyhashString(*(*string)(unsafe.Pointer(&key)))
		}
	default:
		hasher = func(key K) uint64 {
			switch k := any(key).(type) {
			case uint:
				//nolint:gosec // G115: intentional bit reinterpretation for hashing
				return hashInt64(int64(k))
			case uint64:
				//nolint:gosec // G115: intentional bit reinterpretation for hashing
				return hashInt64(int64(k))
			case string:
				return wyhashString(k)
			case fmt.Stringer:
				return wyhashString(k.String())
			default:
				return wyhashString(fmt.Sprintf("%v", k))
			}
		}
	}

	for i := range nshards {
		ghostCap := max(int(float64(shardCap)*ghostRatio), 1)
		cache.shards[i] = &shard[K, V]{
			capacity:        shardCap,
			ghostCap:        ghostCap,
			entries:         make(map[K]*entry[K, V], shardCap),
			ghostActive:     newBloomFilter(ghostCap, 0.00001),
			ghostAging:      newBloomFilter(ghostCap, 0.00001),
			ghostFreqActive: make(map[uint64]uint32, ghostCap),
			ghostFreqAging:  make(map[uint64]uint32, ghostCap),
			hasher:          hasher,
			parent:          cache,
		}
	}

	return cache
}

func (s *shard[K, V]) newEntry() *entry[K, V] {
	if s.freeEntries != nil {
		e := s.freeEntries
		s.freeEntries = e.next
		e.next = nil
		e.prev = nil
		return e
	}
	return &entry[K, V]{}
}

func (s *shard[K, V]) putEntry(e *entry[K, V]) {
	var (
		zeroK K
		zeroV V
	)
	e.key = zeroK
	e.value = zeroV
	e.expiryNano = 0
	e.freq.Store(0)
	e.peakFreq.Store(0)
	e.inSmall = false
	e.prev = nil
	e.next = s.freeEntries
	s.freeEntries = e
}

// shard returns the shard for a given key using type-optimized hashing.
// Uses bitwise AND with shardMask for fast modulo (numShards must be power of 2).
func (c *s3fifo[K, V]) shard(key K) *shard[K, V] {
	// Fast paths for common key types avoid type switch overhead.
	if c.keyIsInt {
		//nolint:gosec // G115: intentional wrap for fast modulo
		return c.shards[uint64(*(*int)(unsafe.Pointer(&key)))&c.shardMask]
	}
	if c.keyIsInt64 {
		//nolint:gosec // G115: intentional wrap for fast modulo
		return c.shards[uint64(*(*int64)(unsafe.Pointer(&key)))&c.shardMask]
	}
	if c.keyIsString {
		return c.shards[wyhashString(*(*string)(unsafe.Pointer(&key)))&c.shardMask]
	}
	// Fallback for other key types
	switch k := any(key).(type) {
	case uint:
		return c.shards[uint64(k)&c.shardMask]
	case uint64:
		return c.shards[k&c.shardMask]
	case string:
		return c.shards[wyhashString(k)&c.shardMask]
	case fmt.Stringer:
		return c.shards[wyhashString(k.String())&c.shardMask]
	default:
		return c.shards[wyhashString(fmt.Sprintf("%v", key))&c.shardMask]
	}
}

// get retrieves a value from the cache.
// On hit, increments frequency counter (used during eviction).
// Uses RLock for full read parallelism - eviction sampling approximates LRU.
func (c *s3fifo[K, V]) get(key K) (V, bool) {
	if c.keyIsString {
		s := c.shards[wyhashString(*(*string)(unsafe.Pointer(&key)))&c.shardMask]
		s.mu.RLock()
		ent, ok := s.entries[key]
		if !ok {
			s.mu.RUnlock()
			var zero V
			return zero, false
		}
		val := ent.value
		expiry := ent.expiryNano
		s.mu.RUnlock()

		if expiry != 0 && time.Now().UnixNano() > expiry {
			var zero V
			return zero, false
		}

		if ent.freq.Load() < maxFreq {
			newFreq := ent.freq.Add(1)
			// Track peak frequency for ghost restore (best-effort, CAS-free for perf)
			if newFreq > ent.peakFreq.Load() {
				ent.peakFreq.Store(newFreq)
			}
		}
		return val, true
	}
	if c.keyIsInt {
		//nolint:gosec // G115: intentional wrap for fast modulo
		s := c.shards[uint64(*(*int)(unsafe.Pointer(&key)))&c.shardMask]
		s.mu.RLock()
		ent, ok := s.entries[key]
		if !ok {
			s.mu.RUnlock()
			var zero V
			return zero, false
		}
		val := ent.value
		expiry := ent.expiryNano
		s.mu.RUnlock()

		if expiry != 0 && time.Now().UnixNano() > expiry {
			var zero V
			return zero, false
		}

		if ent.freq.Load() < maxFreq {
			newFreq := ent.freq.Add(1)
			// Track peak frequency for ghost restore (best-effort, CAS-free for perf)
			if newFreq > ent.peakFreq.Load() {
				ent.peakFreq.Store(newFreq)
			}
		}
		return val, true
	}
	return c.shard(key).get(key)
}

func (s *shard[K, V]) get(key K) (V, bool) {
	s.mu.RLock()
	ent, ok := s.entries[key]
	if !ok {
		s.mu.RUnlock()
		var zero V
		return zero, false
	}

	// Read values while holding lock to avoid race with concurrent set()
	val := ent.value
	expiry := ent.expiryNano
	s.mu.RUnlock()

	// Check expiration (lazy - actual cleanup happens in background)
	if expiry != 0 && time.Now().UnixNano() > expiry {
		var zero V
		return zero, false
	}

	// S3-FIFO: increment frequency for promotion decisions.
	// Skip if already at max to reduce contention on hot keys.
	if ent.freq.Load() < maxFreq {
		newFreq := ent.freq.Add(1)
		// Track peak frequency for ghost restore (best-effort, CAS-free for perf)
		if newFreq > ent.peakFreq.Load() {
			ent.peakFreq.Store(newFreq)
		}
	}

	return val, true
}

// set adds or updates a value in the cache.
// expiryNano is Unix nanoseconds; 0 means no expiry.
func (c *s3fifo[K, V]) set(key K, value V, expiryNano int64) {
	if c.keyIsString {
		h := wyhashString(*(*string)(unsafe.Pointer(&key)))
		c.shards[h&c.shardMask].setWithHash(key, value, expiryNano, h)
		return
	}
	if c.keyIsInt {
		//nolint:gosec // G115: intentional wrap for fast modulo
		c.shards[uint64(*(*int)(unsafe.Pointer(&key)))&c.shardMask].set(key, value, expiryNano)
		return
	}
	c.shard(key).set(key, value, expiryNano)
}

func (s *shard[K, V]) set(key K, value V, expiryNano int64) {
	s.setWithHash(key, value, expiryNano, 0)
}

// setWithHash is like set but accepts a pre-computed hash for ghost checks.
// If hash is 0, it will be computed when needed.
func (s *shard[K, V]) setWithHash(key K, value V, expiryNano int64, hash uint64) {
	s.mu.Lock()

	// Fast path: update existing entry
	if ent, ok := s.entries[key]; ok {
		ent.value = value
		ent.expiryNano = expiryNano
		if ent.freq.Load() < maxFreq {
			newFreq := ent.freq.Add(1)
			// Track peak frequency for ghost restore
			if newFreq > ent.peakFreq.Load() {
				ent.peakFreq.Store(newFreq)
			}
		}
		s.mu.Unlock()
		return
	}

	// Slow path: insert new key (already holding lock)

	// Create new entry
	ent := s.newEntry()
	ent.key = key
	ent.value = value
	ent.expiryNano = expiryNano

	// Check if cache is at capacity
	full := s.parent.totalEntries.Load() >= int64(s.parent.capacity)

	// Warmup Bypass: During warmup, admit everything to small queue without eviction
	if !s.warmupComplete && !full {
		ent.inSmall = true
		s.small.pushBack(ent)
		s.entries[key] = ent
		s.parent.totalEntries.Add(1)
		s.mu.Unlock()
		return
	}
	// Mark warmup complete once we've reached capacity
	s.warmupComplete = true

	// Lazily check ghost only if at capacity (when eviction matters)
	// This saves 2× bloom filter checks + hash computation when cache isn't full
	if full {
		// Use pre-computed hash if provided, otherwise compute
		h := hash
		if h == 0 {
			h = s.hasher(key)
		}
		inGhost := s.ghostActive.Contains(h) || s.ghostAging.Contains(h)
		ent.inSmall = !inGhost

		// If returning from ghost, restore peak frequency with 50% penalty
		if inGhost {
			var peakFreq uint32
			if f, ok := s.ghostFreqActive[h]; ok {
				peakFreq = f
			} else if f, ok := s.ghostFreqAging[h]; ok {
				peakFreq = f
			}
			// Restore 50% of peak frequency (rounded down)
			restoredFreq := peakFreq / 2
			if restoredFreq > 0 {
				ent.freq.Store(restoredFreq)
				ent.peakFreq.Store(restoredFreq) // Also restore peak
			}
		}

		// Evict one entry to make room
		if s.main.len > 0 && s.small.len <= s.capacity/10 {
			s.evictFromMain()
		} else if s.small.len > 0 {
			s.evictFromSmall()
		}
	} else {
		// Cache not full, always insert to small queue
		ent.inSmall = true
	}

	// Add to appropriate queue
	if ent.inSmall {
		s.small.pushBack(ent)
	} else {
		s.main.pushBack(ent)
	}

	s.entries[key] = ent
	s.parent.totalEntries.Add(1)
	s.mu.Unlock()
}

// del removes a value from the cache.
func (c *s3fifo[K, V]) del(key K) {
	c.shard(key).delete(key)
}

func (s *shard[K, V]) delete(key K) {
	s.mu.Lock()
	defer s.mu.Unlock()

	ent, ok := s.entries[key]
	if !ok {
		return
	}

	if ent.inSmall {
		s.small.remove(ent)
	} else {
		s.main.remove(ent)
	}

	delete(s.entries, key)
	s.putEntry(ent)
	s.parent.totalEntries.Add(-1)
}

// evictFromSmall evicts an entry from the small queue.
// Checks the front entry and evicts if cold (freq < 2), otherwise promotes to main.
func (s *shard[K, V]) evictFromSmall() {
	mainCap := (s.capacity * 9) / 10 // 90% for main queue

	for s.small.len > 0 {
		e := s.small.head
		freq := e.freq.Load()

		// Cold entry (freq < 2): evict and add to ghost
		if freq < 2 {
			s.small.remove(e)
			k := e.key
			peakFreq := e.peakFreq.Load()
			delete(s.entries, k)

			h := s.hasher(k)
			if !s.ghostActive.Contains(h) {
				s.ghostActive.Add(h)
				s.ghostFreqActive[h] = peakFreq
			}
			if s.ghostActive.entries >= s.ghostCap {
				s.ghostAging.Reset()
				s.ghostFreqAging = make(map[uint64]uint32, s.ghostCap)
				s.ghostActive, s.ghostAging = s.ghostAging, s.ghostActive
				s.ghostFreqActive, s.ghostFreqAging = s.ghostFreqAging, s.ghostFreqActive
			}

			s.putEntry(e)
			s.parent.totalEntries.Add(-1)
			return
		}

		// Warm entry: promote to main queue
		s.small.remove(e)
		e.freq.Store(0)
		e.inSmall = false
		s.main.pushBack(e)

		if s.main.len > mainCap {
			s.evictFromMain()
		}
	}
}

// evictFromMain evicts an entry from the main queue.
// Checks the front entry and evicts if cold (freq == 0), otherwise gives second chance.
func (s *shard[K, V]) evictFromMain() {
	for s.main.len > 0 {
		e := s.main.head
		freq := e.freq.Load()

		// Cold entry (freq == 0): evict and add to ghost
		if freq == 0 {
			s.main.remove(e)
			k := e.key
			peakFreq := e.peakFreq.Load()
			delete(s.entries, k)

			h := s.hasher(k)
			if !s.ghostActive.Contains(h) {
				s.ghostActive.Add(h)
				s.ghostFreqActive[h] = peakFreq
			}
			if s.ghostActive.entries >= s.ghostCap {
				s.ghostAging.Reset()
				s.ghostFreqAging = make(map[uint64]uint32, s.ghostCap)
				s.ghostActive, s.ghostAging = s.ghostAging, s.ghostActive
				s.ghostFreqActive, s.ghostFreqAging = s.ghostFreqAging, s.ghostFreqActive
			}

			s.putEntry(e)
			s.parent.totalEntries.Add(-1)
			return
		}

		// Warm entry: give second chance (decrement freq and move to back)
		s.main.remove(e)
		e.freq.Store(freq - 1)
		s.main.pushBack(e)
	}
}

// len returns the total number of entries across all shards.
func (c *s3fifo[K, V]) len() int {
	total := 0
	for i := range c.shards {
		s := c.shards[i]
		s.mu.Lock()
		total += len(s.entries)
		s.mu.Unlock()
	}
	return total
}

// flush removes all entries from all shards.
func (c *s3fifo[K, V]) flush() int {
	total := 0
	for i := range c.shards {
		total += c.shards[i].flush()
	}
	// Reset global counter
	c.totalEntries.Store(0)
	return total
}

func (s *shard[K, V]) flush() int {
	s.mu.Lock()
	defer s.mu.Unlock()

	n := len(s.entries)
	s.entries = make(map[K]*entry[K, V], s.capacity)
	s.small.head, s.small.tail, s.small.len = nil, nil, 0
	s.main.head, s.main.tail, s.main.len = nil, nil, 0
	s.ghostActive.Reset()
	s.ghostAging.Reset()
	s.ghostFreqActive = make(map[uint64]uint32, s.ghostCap)
	s.ghostFreqAging = make(map[uint64]uint32, s.ghostCap)
	return n
}
